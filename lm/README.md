# Language Model Experiments

Follow Karpathy's GPT-2 from scratch: [here](https://www.youtube.com/watch?v=l8pRSuU81PU) (Get GPT-2 level model for $10)
My notes and mistakes following this video: [here]()


Notes: 
* GPT paper: https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf
* OpenAI gpt2 paper: https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf
* gpt2 code: https://github.com/openai/gpt-2
* gpt3 paper: https://arxiv.org/abs/2005.14165
* Hugging Face GPT-2: https://huggingface.co/openai-community/gpt2
* Attention is all you need: https://arxiv.org/pdf/1706.03762


After I have a model, I plan to do the following experiments with it:
1. Interpretability 
2. Make it a BitNet network
3. Make Matmul-free model from it?
4. Basic ops
5. LLM Applications
6. Use a tiny model for RAG for fun
7. Running other benchmarks

